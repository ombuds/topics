{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# Always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data for Spacy's TextCategorizer\n",
    "\n",
    "### Import statements and logging initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:making final data set from raw data\n"
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import random\n",
    "import thinc.extra.datasets\n",
    "from src.data import make_dataset\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.info('making final data set from raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Yahoo! dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Number of training samples:    3543746\nINFO:root:Number of test     samples:     151860\nWall time: 36 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "# load the data\n",
    "train,test,classes=make_dataset.untar(\"../data/raw/yahoo_answers_csv.tar.gz\")\n",
    "data_train = make_dataset.straighten(train)\n",
    "data_test  = make_dataset.straighten(test )\n",
    "# print statistics\n",
    "logging.info(f\"Number of training samples: {len(data_train):10}\")\n",
    "logging.info(f\"Number of test     samples: {len(data_test ):10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class balancing\n",
    "\n",
    "The dataset is almost already balanced, with the exception of the missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          title  qtext  answer   class\nclassid                               \n1        140000  86080  138700  140000\n2        140000  67706  139991  140000\n3        140000  79640  136996  140000\n4        140000  69812  137633  140000\n5        140000  78944  134149  140000\n6        140000  65922  139890  140000\n7        140000  64038  137916  140000\n8        140000  81536  137577  140000\n9        140000  92409  133902  140000\n10       140000  82238  138667  140000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>qtext</th>\n      <th>answer</th>\n      <th>class</th>\n    </tr>\n    <tr>\n      <th>classid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>140000</td>\n      <td>86080</td>\n      <td>138700</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>140000</td>\n      <td>67706</td>\n      <td>139991</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140000</td>\n      <td>79640</td>\n      <td>136996</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>140000</td>\n      <td>69812</td>\n      <td>137633</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>140000</td>\n      <td>78944</td>\n      <td>134149</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>140000</td>\n      <td>65922</td>\n      <td>139890</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>140000</td>\n      <td>64038</td>\n      <td>137916</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>140000</td>\n      <td>81536</td>\n      <td>137577</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>140000</td>\n      <td>92409</td>\n      <td>133902</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>140000</td>\n      <td>82238</td>\n      <td>138667</td>\n      <td>140000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train.groupby(['classid']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare figures with the thinc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Number of training samples:      25000\n"
    }
   ],
   "source": [
    "thinc_data, _ = thinc.extra.datasets.imdb()           # TODO: Replace with text extraction: list of tuples (text,class) <-- not needed\n",
    "logging.info(f\"Number of training samples: {len(thinc_data):10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict the training set to a random subset\n",
    "\n",
    "Seed the random call with `SEED_TRAINING_SET_SAMPLER` to allow repetitive training.\n",
    "\n",
    "Also set the training set size `limit` to enforce the same dataset size as in spacy's example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition off part of the train data for evaluation\n",
    "random.shuffle(thinc_data)                            # TODO: Add seed control\n",
    "thinc_data = thinc_data[-limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_TRAINING_SET_SAMPLER = 101\n",
    "# Create a seedable random shuffler\n",
    "random_shuffler = random.Random(SEED_TRAINING_SET_SAMPLER)\n",
    "# Combine texts with their categories to shuffle them together, then sumsample a random training set\n",
    "# TODO: replace this subsampling step with a balanced sampling from each class\n",
    "random_shuffler.shuffle( data_train )\n",
    "data_train = data_train[-limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the categories dictionary for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the 1D arrays X into lists and the Y array into categories, using the classes list [{\"CLASS1\":1,\"CLASS2\":2,...}]\n",
    "texts, labels = zip(*thinc_data)\n",
    "cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]      # TODO: Replace with classes: list of dict with true/false value for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the 1D arrays X into lists and the Y array into categories, using the classes list [{\"CLASS1\":1,\"CLASS2\":2,...}]\n",
    "texts, labels = zip(*data_train)\n",
    "cats=[ pd.DataFrame(classes['classid']==y,index=classes['class']).to_dict()['classid'] for y in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the categories list for text 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "({'Society & Culture': nan,\n  'Science & Mathematics': nan,\n  'Health': nan,\n  'Education & Reference': nan,\n  'Computers & Internet': nan,\n  'Sports': nan,\n  'Business & Finance': nan,\n  'Entertainment & Music': nan,\n  'Family & Relationships': nan,\n  'Politics & Government': nan},\n 8)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "cats[32], labels[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training set into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(thinc_data) * split)\n",
    "# return (texts[:split], cats[:split]), (texts[split:], cats[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data_train) * split)\n",
    "# return (texts[:split], cats[:split]), (texts[split:], cats[split:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('spacy': conda)",
   "language": "python",
   "name": "python37764bitspacycondadadf2b73d41940a8a7f37c607b76324d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}